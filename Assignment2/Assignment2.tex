\documentclass[11pt,letter, swedish, english
]{article}
\pdfoutput=1

\usepackage{custom_as}



%%Drar in tabell och figurtexter
\usepackage[margin=10 pt]{caption}
%%För att lägga in 'att göra'-noteringar i texten
\usepackage{todonotes} %\todo{...}

%%För att själv bestämma marginalerna. 
\usepackage[
%            top    = 3cm,
%            bottom = 3cm,
%            left   = 3cm, right  = 3cm
]{geometry}

%%För att ändra hur rubrikerna ska formateras
\renewcommand{\thesubsection}{\arabic{section} (\alph{subsection})}

\renewcommand{\thesubsubsection}{\arabic{section} (\alph{subsection},\,\roman{subsubsection})}

% \newcommand{\cbox}[2][cyan]
% {\mathchoice
% 	{\setlength{\fboxsep}{0pt}\colorbox{#1}{$\displaystyle#2$}}
% 	{\setlength{\fboxsep}{0pt}\colorbox{#1}{$\textstyle#2$}}
% 	{\setlength{\fboxsep}{0pt}\colorbox{#1}{$\scriptstyle#2$}}
% 	{\setlength{\fboxsep}{0pt}\colorbox{#1}{$\scriptscriptstyle#2$}}
% }
% \newcommand{\grande}{\cbox{\phantom{\frac{1}{xx}}}}


\begin{document}

%%%%%%%%%%%%%%%%% vvv Inbyggd titelsida vvv %%%%%%%%%%%%%%%%%
% \begin{titlepage}
\title{Quantum Mechanics -- PHYS\,701 \\
Assignment 2}
\author{Andréas Sundström}
\date{\today}

\maketitle

%%%%%%%%%%%%%%%%% ^^^ Inbyggd titelsida ^^^ %%%%%%%%%%%%%%%%%

%Om man vill ha en lista med vilka todo:s som finns.
%\todolist

\section{The uncertainty relation}

\subsection{The Schwarz inequality}
Here we're looking to derive the Schwarz inequality:
\begin{equation}\label{eq:schwarz}
\braket{\alpha}\braket{\beta} \ge \abs{\braket{\alpha}{\beta}}^2.
\end{equation}


We begin by observing that
\begin{equation}\label{eq:ineq1}
\big( \bra{\alpha} + \lambda^*\bra{\beta} \big) \cdot
\big( \ket{\alpha} + \lambda\ket{\beta} \big) \ge 0
\end{equation}
for any $\lambda\in\C$ and any $\ket{\alpha}$ and $\ket{\beta}$. This
is true because the LHS is just $\braket{\gamma}$ with
$\ket{\gamma}=\ket{\alpha}+\lambda^*\ket{\beta}$, so the inequality
is by axiom. 

This can then be expanded to:
\begin{equation}\label{eq:ineq2}
\braket{\alpha} + \lambda \braket{\alpha}{\beta} +
\lambda^*\braket{\beta}{\alpha} + \abs{\lambda}^2\braket{\beta} \ge 0.
\end{equation}
Before we continue let's introduce some shorter notation:
\begin{equation}\label{eq:short_notation}
\begin{aligned}
\braket{\alpha}=:a \qcomma& \braket\beta := b \\
\braket{\alpha}{\beta}=:r_0\ee^{\ii\phi_0}\qcomma & \lambda = -\rho\ee^{\ii\theta},
\end{aligned}
\end{equation}
where $a$, $b$, $r_0$ and $\rho$ are all real and non-negative.
Pleas also note that although $\ket\alpha$ and $\ket\beta$ are
arbitrary, the only ``free'' parameters here are $\rho$ and $\theta$.

Now the LHS of \eqref{eq:ineq2} looks like
\begin{equation}
a -\rho r_0\,\ee^{\ii(\theta + \phi_0)} 
-\rho r_0\,\ee^{-\ii(\theta+\phi_0)} + \rho^2b 
= a - \rho r_0 2\cos(\theta+\phi_0) + \rho^2b \ge 0.
\end{equation}
By choosing $\rho=\nicefrac{r_0}{b}$ and moving part of the LSH to
the RHS, we get
\begin{equation}
a \ge  \frac{r_0^2}{b} 2\cos(\theta+\phi_0) - \frac{r_0^2}{b^2}b 
= \frac{r_0^2}{b} \Big( 2\cos(\theta+\phi_0) - 1 \Big).
\end{equation}
Mulitplying both side by $b$ (which is non-negative) and setting
$\theta=-\phi_0$, the expression becomes
\begin{equation}
ab \ge r_0^2,
\end{equation}
which with \eqref{eq:short_notation} is precisely the Schwarz
inequality:
\begin{equation}
\braket{\alpha}\braket{\beta} \ge \abs{\braket{\alpha}{\beta}}^2.
\end{equation}
\qed

\subsection{An equality in the generalized uncertainty relation}
For any given state $\ket{\alpha}$ and observables (Hermitian
operators) $A$ and $B$, the generalized uncertainty relation states that
\begin{equation} \label{eq:uncertainty}
\ev{(\Delta{A})^2}{\alpha}\ev{(\Delta{B})^2}{\alpha} 
\ge \frac{1}{4} \abs{\ev{\comm{A}{B}}{\big.\alpha}}^2.
\end{equation}
We shall here show that, if the state $\ket{\alpha}$ satisfies
\begin{equation}
\Delta{A}\ket{\alpha}=\lambda \Delta{B}\ket{\alpha}\qcomma \lambda \in \ii\R,
\end{equation}
the inequality becomes an equality.

First of all we note that $\comm{A}{B}=\comm{\Delta{A}}{\Delta{B}}$,
since $\Delta{A}$ and $\Delta{B}$ are just $A$ and $B$ respectively
shifted by a constant number. Therefore we can write the RHS of
\eqref{eq:uncertainty} as
\begin{equation}
\begin{aligned}
\frac{1}{4} \abs{\ev**{\comm{\Delta{A}}{\Delta{B}}}{\alpha}}^2 
=& \frac{1}{4} 
  \abs{\ev**{\Delta{A}\Delta{B} -\Delta{B}\Delta{A}}{\alpha}}^2 \\
=& \frac{1}{4} \abs{
    \ev**{\lambda^*\Delta{B}\Delta{B} - \lambda\Delta{B}\Delta{B}}{\alpha}
   }^2\\
=& \frac{1}{4} \Big| \underbrace{\big(\lambda^*-\lambda\big)}_{-2\Im(\lambda)}
\ev**{(\Delta{B})^2}{\alpha} \Big|^2.
\end{aligned}
\end{equation}
We can now turn our attension to the LHS of
\eqref{eq:uncertainty}. There it's just a matter of rewiting the first
factor
\begin{equation}
\ev{(\Delta{A})^2}{\alpha} 
= \ev{\lambda^*\Delta{B}\;\lambda\Delta{B}}{\alpha} 
= \abs{\lambda}^2 \ev{\Delta{B}}{\alpha}.
\end{equation}

It is now clear that if $(\Im(\lambda))^2=\abs{\lambda}^2$, we would
get an equality in \eqref{eq:uncertainty}. This is however precisely
the case here, since $\lambda\in\ii\R$. We therefore have
\begin{equation} 
\ev{(\Delta{A})^2}{\alpha}\ev{(\Delta{B})^2}{\alpha} 
= \frac{1}{4} \abs{\ev**{\comm{A}{B}}{\big.\alpha}}^2
\end{equation}
in this situation.\qed

\subsection{Uncertainty in a Gaußian wave packet}
We are given the (position) wave function of a 1D Gaußian wave packet
\begin{equation}
\psi_\alpha(x'') = \braket{x''}{\alpha} 
= C'' \exp[\frac{\ii\ev{p}x''}{\hbar}-\frac{\big(x''-\ev{x}\!\big)^2}{4d^2}]
\end{equation}
with some normaization constant $C''$. For simplicity we can easily
change coordiantes as follows
\begin{equation}
\begin{aligned}
x'' \longmapsto&\; x'=x''-\ev{x}\\
\phi_\alpha(x'') \longmapsto&\; \phi_\alpha(x') 
= C' \exp[\frac{\ii\ev{p}x'}{\hbar}-\frac{x'^2}{4d^2}],
\end{aligned}
\end{equation}
where the coordinate change only altered the wave function by
changing the normailzation constant by a constant complex phase. This
shift in the position coordinates gives us $\ev{x}=0$.

We now want to show that $\Delta{p}\ket{\alpha}$ only differs to
$\Delta{x}\ket{\alpha}$ by some imaginary factor. To do this we stude
the effect of the two operators on the wave function (in the position
basis). 

Clearly the the effects of $\Delta{x}=x-\ev{x}=x$ is given by
\begin{equation}
\bra{x'}\Delta{x}\ket{\alpha} = \bra{x'}x\ket{\alpha} = x'\phi_\alpha{x'}
\end{equation}
since $\phi_\alpha$ is in the position basis. 

The effects of $\Delta{p}$ is easily found by applying the property of
the momentum operator on a wave function in the position basis:
\begin{equation}
\bra{x'}p\ket{\alpha} = -\ii\hbar \pdv{x'} \braket{x'}{\alpha} 
= -\ii\hbar \pdv{x'} \phi_\alpha(x').
\end{equation}
This is known from earlier courses in quantum mechanics, or from
Sakurai~\&~Napolitano, \textit{Modern Quantum Mechanics}, 2$^\text{nd}$
ed., eqn. (1.7.17). This now gives us
\begin{equation}
\begin{aligned}
\mel{x'}{\Delta{p}}{\alpha} =& \mel**{x'}{\big(p-\ev{p}\big)}{\alpha}\\
=& \left[-\ii\hbar \pdv{x'} - \ev{p}\right] \phi_\alpha(x')\\
=& \left(
   -\ii\hbar\left[ \frac{\ii\ev{p}}{\hbar} - \frac{2x'}{4d}\right] 
   - \ev{p}\right)\cdot \phi_\alpha(x')\\
=& \ii\frac{x'}{2d\hbar}\phi_\alpha(x').
\end{aligned}
\end{equation}
The derivative was evaluated with the fact that the exponential
differentiatied yields itself times the inner derivative.\qed

To conclude we can see that
\begin{equation}
\bra{x'}\Delta{x}\ket{\alpha} = \frac{\ii}{2d\hbar} \bra{x'}\Delta{p}\ket{\alpha},
\end{equation}
meaning that according to part (b) a Gaußian wave packet ideed
satisfies the minimum uncertainty relation.



\section{Uncertainty in spin operators}
In this problem we have the two spin operators
\begin{equation}
\begin{aligned}
S_x &= \phantom{-\ii}\frac{\hbar}{2}\Big[\big(\ketbra{+}{-}\big) + \big(\ketbra{-}{+}\big) \Big]\\
S_y &= -\ii\frac{\hbar}{2}\Big[\big(\ketbra{+}{-}\big) - \big(\ketbra{-}{+}\big) \Big].
\end{aligned}
\end{equation}
Now we're tasked to maximize the uncertinty product
\begin{equation}
\ev{\left(\Delta{S_x}\right)^2}\ev{\left(\Delta{S_y}\right)^2},
\end{equation}
by choosing some linear combination state
\begin{equation}
\ket{\psi}=\alpha\ket{+}+\beta\ket{-} 
   \qcomma \alpha,\beta\in\C \text{ and } |\alpha|^2+|\beta|^2 = 1.
\end{equation}
The last condition is a nomalization condition $\braket{\psi}=1$.

Before we continue, let's introduce a matrix representation in the
problem. Let
\begin{equation}
\ket{+} \dot= \begin{pmatrix} 1\\0 \end{pmatrix}
\qcomma \ket{-} \dot= \begin{pmatrix} 0\\1 \end{pmatrix},
\end{equation}
giving us the matrix representations of the spin operators
\begin{equation}
S_x \dot= \frac{\hbar}{2}\begin{pmatrix} 0&1\\1&0 \end{pmatrix}
\qcomma
S_y \dot= \ii\frac{\hbar}{2}\begin{pmatrix*}[r] 0&-1\\1&0 \end{pmatrix*},
\end{equation}
and our linear combination state is
\begin{equation}
\ket{\psi} \dot= \begin{pmatrix} \alpha\\\beta \end{pmatrix}.
\end{equation}

To calculate the uncertainty product, we have to go through and
calculate four different quantities: $\ev*{S_x}$, $\ev*{S_x^2}$, 
$\ev*{S_y}$ and $\ev*{S_y^2}$.
\begin{enumerate}[label=(\roman*)]
\item $\displaystyle{ 
\ev**{S_x}{\psi} = \frac{\hbar}{2} 
\begin{pmatrix}\alpha^*&\beta^*\end{pmatrix}
\begin{pmatrix}0&1\\1&0\end{pmatrix}
\begin{pmatrix}\alpha\\\beta\end{pmatrix}
= \frac{\hbar}{2} \overbrace{\left(\alpha^*\beta + \alpha\beta^*\right)}^{2\Re(\alpha\beta^*)},
}$
\item $\displaystyle{ 
\ev**{S_x^2}{\psi} = \frac{\hbar^2}{4} 
\begin{pmatrix}\alpha^*&\beta^*\end{pmatrix}
\begin{pmatrix}1&0 \\ 0&1\end{pmatrix}
\begin{pmatrix}\alpha \\ \beta\end{pmatrix}
= \frac{\hbar^2}{4} \left( |\alpha|^2+|\beta|^2 \right) 
= \frac{\hbar^2}{4},
}$
\item $\displaystyle{ 
\ev**{S_y}{\psi} = \ldots 
=\ii\frac{\hbar}{2}\overbrace{\left(-\alpha^*\beta + \alpha\beta^*\right)}^{2\Im(\alpha\beta^*)},
}$
\item $\displaystyle{ 
\ev**{S_x^2}{\psi} = \ldots = \frac{\hbar^2}{4}.
}$
\end{enumerate}
The last two calculations have been left out due to their close
resemblance to the first two respectivley. We can also note that
$\ev*{S_x}$ and $\ev*{S_y}$ seems to contain a factor of the real and
imaginary part respectivley of the complex number
\begin{equation}
\alpha\beta^*=:\frac{1}{2} \big(\xi+\ii\eta\big).
\end{equation}
Here $\xi$ and $\eta$ are defined as 2 times the real and imaginary
part of $\alpha\beta^*$ respectivly. Note that $\xi, \eta \in\R$.

The uncertainty product can now be evaluated:
\begin{equation} \label{eq:unc_prod}
\begin{aligned}
\ev{\left(\Delta{S_x}\right)^2}\ev{\left(\Delta{S_y}\right)^2}
&= \ev**{S_x^2-\ev{S_x}^2}{\psi}\ev**{S_y^2-\ev{S_y}^2}{\psi} \\
&= \left[\frac{\hbar^2}{4}-\left(\frac{\hbar}{2}\xi\right)^2\right]
   \left[\frac{\hbar^2}{4}-\left(\ii\frac{\hbar}{2}\eta\right)^2\right]\\
&= \frac{\hbar^4}{16}\left(1 - \xi^2\right)\left(1 + \eta^2\right).
\end{aligned}
\end{equation}
Now since $\alpha$ and $\beta$ are constrained by the normalization,
it's easy to note that
\begin{equation} \label{eq:constraint}
\frac{1}{2}\abs{\xi+\ii\eta} = \abs{\alpha\beta^*}=\abs{\alpha}\abs{\beta}\le\frac{1}{2},
\end{equation}
where maximum is obtained when $\abs{\alpha}=\abs{\beta}=2^{-1/2}$.
From \eqref{eq:constraint} it's easy to see that $\abs{\xi}\le1$ and
$\abs{\eta}\le1$. The fact that $\abs{\xi}\le1$ shows us that to
maximize \eqref{eq:unc_prod}, we should choose $\xi=0$ and
$\abs{\eta}=1$. This can be realized by choosing
\begin{equation}
\alpha=\frac{1}{\sqrt{2}}\quad\text{and}\quad\beta=\frac{\pm\ii}{\sqrt{2}},
\end{equation}
any other solution is just a constant complex phase added to the one
above. \qed

We're also asked to explicitly verify that the uncertainty relation
\eqref{eq:uncertainty}, for $S_x$ and $S_y$, is not violated in this
case. The LHS is given by \eqref{eq:unc_prod} to be
\begin{equation}
\ev{\left(\Delta{S_x}\right)^2}\ev{\left(\Delta{S_y}\right)^2}
= \frac{\hbar^4}{8}.
\end{equation}
While the RHS is given by
\begin{equation}
\begin{aligned}
\frac{1}{4}\abs{\ev{\comm{S_x}{S_y}}{\psi}}^2
&= \frac{1}{4} \abs{
   \ii\frac{\hbar^2}{4}
   \begin{pmatrix}\alpha^*&\beta^*\end{pmatrix}
   \left[
     \begin{pmatrix}1&0\\0&-1\end{pmatrix}-\begin{pmatrix}-1&0\\0&1\end{pmatrix}
   \right]
   \begin{pmatrix}\alpha\\\beta\end{pmatrix}
 }^2\\
&= \frac{1}{4} \abs{
   \ii\frac{\hbar^2}{4}\cdot2\cdot\frac{1^2-\ii^2}{2}
 }^2= \frac{\hbar^4}{16},
\end{aligned}
\end{equation}
which is clearly less than the LHS. So the uncertainty relation for
$S_x$ and $S_y$ is \emph{not} violated in this case.



\section{Commutators involving $x$ and $p_x$}

\subsection{The calssical case}
It's pretty straight forward to evaluate the Poisson bracket here:
\begin{equation}
\comm{x}{F(x_x)}_\text{classical} 
= \pdv{x}{x}\pdv{F(p_x)}{p} - \pdv{x}{p}\pdv{F(p_x)}{x} 
= \pdv{F(p_x)}{p}.
\end{equation}

\subsection{Commuting $x$ and an exponential of $p_x$}
This is clearly just a special case of the rule in
problem~\ref{sec:p_power}. With \eqref{eq:p_power} we get
\begin{equation} \label{eq:comm_exp}
\comm{x}{\exp(\frac{\ii p_xa}{\hbar})} 
= \ii\hbar \cdot \frac{\ii a}{\hbar} = -a \exp(\frac{\ii p_xa}{\hbar}).
\end{equation}

\subsection{Inverstigating the effects of the expoential of $p_x$}
To prove that
\begin{equation}
\exp(\frac{\ii p_xa}{\hbar})\ket{x'}
\end{equation}
is an eigenstate of the $x$ operator, we just aply $x$ and se what it
evaluates to:
\begin{equation}
%\begin{aligned}
x\exp(\frac{\ii p_xa}{\hbar})\ket{x'} 
= \left( \comm{x}{\exp(\frac{\ii p_xa}{\hbar})} 
+\exp(\frac{\ii p_xa}{\hbar}) x \right)\ket{x'}.
%\end{aligned}
\end{equation}
From here we make use of the result in \eqref{eq:comm_exp} and the
fact that $x\ket{x'}=x'\ket{x'}$. This gives us
\begin{equation}
x\exp(\frac{\ii p_xa}{\hbar})\ket{x'} 
= \overbrace{(x'-a)}^\text{eigenvalue}
  \underbrace{\exp(\frac{\ii p_xa}{\hbar})\ket{x'}}_\text{eigenstate}.
\end{equation}


\section{More comutators of $x$ and $p_x$}

\subsection{Commutators of $x$ and power series in $p_x$ and vice versa}
Before we set out to prove the two commutator relations, it will be
helpfull to derive an intermediary result first. We're going to prove
the formula
\begin{equation} \label{eq:comm_power}
\comm{A}{B^n} = \sum_{i=0}^{n-1} B^{i}\comm{A}{B}B^{n-1-i}.
\end{equation}
This formula is most readily derived with a proof by induction. 

To start off with, we can clearly see that \eqref{eq:comm_power} holds
in the base case of $n=1$. Then assume that it also holds for all
interger up to some value $m$. Does it then also hold for $m+1$?
To show that it does, use the elementary commutator
indentity
\begin{equation} \label{eq:comm_A_BC}
\comm{A}{BC} = \comm{A}{B}C+B\comm{A}{C},
\end{equation}
which gives
\begin{equation}
\begin{aligned}
\comm{A}{B^{m+1}} &= \comm{A}{B^{m}B} \\
&\hspace{-3pt}\stackrel{\eqref{eq:comm_A_BC}}{=} \comm{A}{B^{m}}B + B^m\comm{A}{B}\\
&\hspace{-14pt}\stackrel{\stackrel{\text{\tiny induction}}{\text{\tiny assumption}}}{=}
\left(\sum_{i=0}^{m-1} B^{i-1}\comm{A}{B}B^{m-1-i}\right) B + B^m\comm{A}{B}\\
&=\sum_{i=0}^{m-1} B^{i-1}\comm{A}{B}B^{m-i} + B^m\comm{A}{B}&=\sum_{i=0}^{m} B^{i-1}\comm{A}{B}B^{m-i}.
\end{aligned}
\end{equation}
The last expression is just \eqref{eq:comm_power} with $n=m+1$. This
concludes the proof by induction. \qed

In our case we will only be interested in cases where $\comm{A}{B}=\lambda$,
where $\lambda$ is some regular number. Then \eqref{eq:comm_power} becomes
\begin{equation} \label{eq:comm_power_c}
\comm{A}{B^n} = \sum_{i=0}^{n-1} \lambda B^{n-1} = n\lambda B^{n-1}.
\end{equation}

\subsubsection{Power series in $p_x$} \label{sec:p_power}
Here we're going to prove the formula
\begin{equation} \label{eq:p_power}
\comm{x_l}{G(\mathbf{p})}=\ii\hbar\pdv{G}{p_l},
\end{equation}
where $G$ is a power series in ints arguments. 

For simplicity lets
assume that $\mathbf{p}$ is (only) 3~dimentional and that $x_l=x$, the proof is
completly analog for any ofther finite dimension pf $\mathbf{p}$ and
choice of $x_l$. 
The power series can thus be expressed as
\begin{equation}
G(\mathbf{p}) 
= \sum_{i=0}^\infty\sum_{j=0}^\infty\sum_{k=0}^\infty
c_{ijk}p_x^ip_y^jp_z^k = \sum_{i=0}^\infty p_x^i \sum_{j,k}c_{ijk}p_y^jp_z^k.
\end{equation}
There is no problems with having to wory about any ordering within
each $p_x^ip_y^jp_z^k$ term, since $\comm{p_l}{p_m}=0$ so that all the
$p$'s commute. Also $x$ commutes with $p_y$ and $p_z$. This means that
the second sum can be viewed as a set of operators
\begin{equation}
C_i=\sum_{j,k}c_{ijk}p_y^jp_z^k
\end{equation}
which \emph{all commute with both} $x$ and $p_x$. The commutator now becomes
\begin{equation}
\comm{x}{G(\mathbf{p})} = \comm{x}{\sum_i C_ip_x^i}=\sum_i C_i \comm{x}{p_x^i}.
\end{equation}
The last step is now to expand the commutator in the RHS using
\eqref{eq:comm_power_c} and $\comm{x}{p_x}=\ii\hbar$:
\begin{equation}
\comm{x}{G(\mathbf{p})} = \sum_{i=1}^\infty C_i (\ii\hbar) ip_x^{i-1}
= \ii\hbar \pdv{p_x}\sum_{i=0}^\infty C_i p_x^{i}
= \ii\hbar \pdv{G(\mathbf{p})}{p_x}.
\end{equation}
\qed


\subsubsection{Power series in $x$}
Here we're tasked to show that
\begin{equation} \label{eq:x_power}
\comm{p_i}{F(\mathbf{x})}=-\ii\hbar\pdv{F}{x_i}.
\end{equation}
For any power series $F$ in terms of it's arguments.

This is proof is completly similar to the one for a power series in
$\mathbf{p}$. Just interchange $x$ and $p_x$ in the proof; the only
change that will happen is that $\comm{p_x}{x}=-\ii\hbar$, giving rise
to the minus sign in \eqref{eq:x_power}.
\qed

\subsection{An example}
Here we're going to evaluate both the classical and quantum mechanical
version of $\comm{x^2}{p_x^2}$:
\begin{equation}
\begin{aligned}
\comm{x^2}{p_x^2} &= \comm{x^2}{p_x}p_x + p_x\comm{x^2}{p_x} 
= \ii\hbar \big( 2xp_x+p_x2x \big) = 2\ii\hbar\acomm{x}{p_x}\\
\comm{x^2}{p_x^2}_\text{classical} 
&= \pdv{(x^2)}{x}\pdv{(p_x^2)}{p_x} - \pdv{(x^2)}{p_x}\pdv{(p_x^2)}{x}
= 4xp_x.
\end{aligned}
\end{equation}
The results are similar, but due to the fact that $x$ and $p_x$
doesn't commute in the quantum mechanica case, it's not possible to
collect the two terms in the anticummutator to one, as is the case in
classical mechanics.



\section{Some useful relations and a little more}

\subsection{Two formulas}

\subsubsection{}
\begin{equation}
\bra{p'}x\ket{\alpha} = \ii\hbar \pdv{p'} \braket{p'}{\alpha}
\end{equation}

\subsubsection{}
\begin{equation}
\bra{\beta}x\ket{\alpha} = \int \rd{p'} \phi^*_\beta(p')\ii\hbar \pdv{p'} \phi_\alpha(p')
\end{equation}



\subsection{A physical interpretation of an exponential of $x$}






\end{document}





%% På svenska ska citattecknet vara samma i både början och slut.
%% Använd två apostrofer (två enkelfjongar): ''.


%% Inkludera PDF-dokument
\includepdf[pages={1-}]{filnamn.pdf} %Filnamnet får INTE innehålla 'mellanslag'!

%% Figurer inkluderade som pdf-filer
\begin{figure}\centering
\centerline{ %centrerar även större bilder
\includegraphics[width=1\textwidth]{filnamn.pdf}
}
\caption{}
\label{fig:}
\end{figure}

%% Figurer inkluderade med xfigs "Combined PDF/LaTeX"
\begin{figure}\centering
\resizebox{.8\textwidth}{!}{\input{filnamn.pdf_t}}
\caption{}
\label{fig:}
\end{figure}

%% Figurer roterade 90 grader
\begin{sidewaysfigure}\centering
\centerline{ %centrerar även större bilder
\includegraphics[width=1\textwidth]{filnamn.pdf}
}
\caption{}
\label{fig:}
\end{sidewaysfigure}


%%Om man vill lägga till något i TOC
\stepcounter{section} %Till exempel en 'section'
\addcontentsline{toc}{section}{\Alph{section}\hspace{8 pt}Labblogg} 

