\chapter{Stokastiska processer och differentialekvationer}

För att beskriva de system som undersöks i det här arbetet
behövs stokastisk analys. Många fysikaliska system kan beskrivas med ordinära eller partiella differential\-ekvationer (ODE:er
eller PDE:er). Tillräckligt små objekts beteende kommer dock att påverkas betydligt av termiska fluktuationer. Dessa termiska fluktuationer kan betraktas som helt
slumpmässiga, varför de då kan beskrivas med \emph{stokastiska processer}. Påverkan på ett system från en stokastisk process leder
till att den styrande differentialekvationen behöver modifieras med en stokastisk term,
det blir då en \emph{stokastisk differentialekvation} (SDE). 
Således introducerar följande avsnitt några viktiga begrepp och metoder 
som används för att studera rörelsen av partiklar i celler samt 
strängar i vätskor. 

Ett exempel på när ett system består av så ''små objekt'' att termiska
fluktuationer behöver beaktas är i så kallad \emph{brownsk rörelse}. 
Detta är ett fenomen där små partiklar vandrar runt slumpmässigt till synes av sig själva. Fenomenet beskrevs först av Robert Brown som 1827~\cite{Brown1828} upptäckte att partiklar från pollenkorn rörde sig hackigt närde flöt på vatten. Fenomenet förklarades först senare av Einstein 1905~\cite{Einstein1905}. Förklaringen går ut på att partiklarna är små nog för att kollisioner med vattenmolekyler ska överföra tillräckligt med rörelsemängd för att pollenkornens rörelseändring ska bli synbar med ett mikroskop. 


\section{Stokastiska processer}
En \emph{stokastisk variabel} $X$ är ett objekt som kan anta värden
$x$ från en viss värdemängd $\Omega$. Vilka värden som antas styrs av
sannolikhetsfördelningen $p(x)=P(X=x)$. I fallet med diskreta stokastiska
variabler är sannolikhetsfördelningen helt enkelt sannolikheten att
$X$ antar värdet $x$. Men i det här arbetet ligger fokus på
kontinuerliga stokastiska variabler. För dessa gäller att sannolikheten för att $X$ antar ett värde i intervallet $[x, x+\dd{x}]$ ges av
\begin{equation}
P(X\in[x, x+\dd{x}]) =p(x)\dd{x}
\end{equation}
för någon infinitesimal intervallbredd $\dd{x}$ och där $p(x)$ är sannolikhetsfördelningen för $X$. 
I fortsättningen av detta arbete kommer ''stokastisk variabel'' att
avse en \emph{kontinuerlig} stokastisk variabel om inget annat anges.


Från detta kan en så kallad \emph{stokastisk process} definieras som en
samling av objekt som beror på en stokastisk variabel $X$ och en
deterministisk variabel, ofta betraktad som en tid\footnotemark{}
$t$. I denna rapport studeras stokastiska processer $Y(t)$ som är funktioner $Y(t) = f(X,t)$, där $X$ följer en sannolikhetsfördelning $p(x)$ och $Y(t)$ hädanefter beror implicit på den stokastiska variabeln $X$.
\footnotetext{Att tiden väljs som deterministisk variabel är
  anledning till att det kallas stokastisk \emph{process}; tanken är att ett tidsförlopp som beror av den stokastiska variabeln
  utspelar sig. Mer generellt kan en godtycklig deterministisk
  variabel användas istället för tid.}  

\subsection{Statistiska verktyg för att undersöka stokastiska processer}
Stokastiska processer är som sagt \emph{slumpartade} processer. Därmed kan
det vara svårt att avgöra processens natur enbart utifrån ett fåtal
observationer. För att kunna undersöka en stokastisk process
behövs olika statistiska verktyg som exempelvis väntevärde, korrelation och spektraltäthet.

\subsubsection{Väntevärde, varians och kovarians}
För en stokastisk variabel $X$ definieras \emph{väntevärdet} med hjälp av variabelns sannolikhetsfördelning $p(x)$ enligt
\begin{equation}\label{eq:EV}
    \ev{X} = \int_{\Omega} x p(x) \id{x}.
\end{equation}
Något löst sett kan det betraktas som det förväntade medelvärdet vid upprepade mätningar av $X$. En av de viktigaste egenskaperna hos väntevärdet är att det är \emph{linjärt}. Alltså att~\cite{Rice_matstat2006}
\begin{equation}\label{eq:EV_linkomb}
\ev{a+\sum_{i=1}^N b_i X_i} = a+\sum_{i=1}^N b_i \ev{X_i}
\end{equation}
för konstanterna $a$ och $b_i$ samt stokastiska variablerna $X_i$. 

Väntevärdet går även att utvidga till att även omfatta funktioner av
den stokastiska variabeln. Vilket ges av~\cite{Rice_matstat2006}
\begin{equation}\label{eq:EV_f}
    \ev{f(X)} = \int_{\Omega} f(x) p(x) \id{x}.
\end{equation}
Speciellt i fallet med stokastiska processer blir väntevärdet 
\begin{equation}\label{eq:EV_process}
    \ev{Y(t)} = \int_{\Omega} Y(t)p(x) \id{x},
\end{equation}
notera att väntevärdet är beroende av $t$. 

Vidare definieras det n:te momentet enligt 
\begin{equation}
    \ev{Y(t_1)Y(t_2)..Y(t_n)} = \int_{\Omega} Y(t_1)Y(t_2)...Y(t_n)p(x)dx.
\end{equation}
Om momentfunktionen är oberoende av en translation i tid $t_i\to t_i+\tau$, där $i=1,2,..n$, för alla val av $n$ och $t_i$ definieras den stokastiska processen som \emph{stationär}. Speciellt är väntevärdet $\ev{Y(t)}$ oberoende av $t$ för en stationär process. 

Om väntevärdet är ett mått på vad man får som medelvärde, så behövs
även ett mått på hur spridda värden man kan tänkas få. För det används
\emph{variansen}, som går att formulera på några olika sätt~\cite{Rice_matstat2006}
\begin{equation}\label{eq:VAR}
\sigma_X^2=\VAR{X} = \ev{\left(X-\ev{X} \right)^2} = \ev{X^2}-\ev{X}^2.
\end{equation}
Dock ger variansen, som man kan se, ett kvadratiskt mått på
avvikelser från medelvärdet. Därför kan det, exempelvis i sammanhang
där man vill jämföra spridningen i en mätserie, vara mer intressant
att betrakta \emph{standardavvikelsen} $\sigma_X$ som ges av roten ur
variansen.


På ett analogt sätt definieras en \emph{kovarians}~\cite{Rice_matstat2006}
\begin{equation}\label{eq:COV}
\COV{X}{Z} 
= \Big\langle \big(\, X-\ev{X}\big)\;\big(\, Z-\ev{Z}\big) \Big\rangle
= \ev{XZ}-\ev{X}\ev{Z}.
\end{equation}
Kovariansen är ett mått på hur mycket två stokastiska variabler
samvarierar. Speciellt syns också att $\COV{X}{X}=\VAR{X}$; alltså att
kovariansen övergår i variansen för $Z=X$. Vidare gäller att om
variablerna är \emph{statisktiskt oberoende} så är kovariansen 0.

För att beräkna variansen av en linjärkombination av stokastiska variabler utnyttjas \eqref{eq:EV_linkomb} tillsammans med definitionerna av varians och kovarians och erhåller
\begin{equation}
\VAR{a+\sum_{i=1}^N b_i X_i} = \VAR{\sum_{i=1}^N b_i X_i} 
= \sum_{i=1}^N\sum_{j=1}^N b_i b_j\, \COV{X_i}{X_j}.
\end{equation}
Om $X_i$ är oberoende, så att $\COV{X_i}{X_j}\propto\delta_{ij}$, kan det sista ledet skrivas om till
\begin{equation}\label{eq:VAR_linkomb}
\VAR{a+\sum_{i=1}^N b_i X_i} = \sum_{i=1}^N b_i^2\, \VAR{X_i}.
\end{equation}




\subsubsection{Korrelationsfunktioner}
I fallet med stokastiska processer kan det vara intressant att veta
hur korrelerade två processer $Y_1(t)$ och $Y_2(t)$ är i till exempel tiden. För det används
korrelationsfunktionen 
\begin{equation}\label{eq:CORR}
c(t, t') = \frac{\COV{Y_1(t)}{Y_2(t')}}{\sigma_{Y_1}\sigma_{Y_2}}.
\end{equation}
Här har kovariansen delats med respektive standardavvikelse för att
korrelationsfuntionen ska ge ett värde mellan $-1$ och $1$, där $1$ motsvarar perfekt korrelation och $-1$ perfekt antikorrelation, vilket följer av Cauchy-Schwarzs\cite{Engelberg_noise2007} olikhet 
\begin{equation}
\sigma_{Y_1}^2\sigma_{Y_2}^2\geq \Big(\COV{Y_1}{Y_2}\Big)^2.
\end{equation}

Om den stokastiska processen är stationär, vilket ofta gäller, innehar korrelationsfunktionen
translationssymmetri i $t$, varför $t$ och $t'$ kan ersättas med deras differens $\Delta t$:
\begin{equation}
c(\Delta t) = c(t, t+\Delta t).
\end{equation}

\subsubsection{Kovariansmatris}
För att studera kovarians mellan flera stokastiska processer $Y_i(t)$, där $i=1,2,..,n$ där $n$ är antalet processer, kan en kovariansmatris definieras där varje element svarar mot kovariansen mellan process $i$ och process $j$. I denna studie används en tidsoberoende kovariansmatris definierad enligt 
\begin{equation}
\label{eq:kovmatris}
    C_{ij} = \COV{Y_i(t)}{Y_j(t)}_t
\end{equation}
där väntevärdet är bildat med avseende på tiden. Om kovariansmatrisen är icke-diagonal är de stokastiska processerna korrelerade. Kovariansmatrisen ses dock enligt denna definition vara symmetrisk samt reell, givet att $Y_i(t)$ är reella stokastiska processer, och således även diagonaliserbar enligt spektralsatsen.  Diagonalisering av kovariansmatrisen åstadkoms genom ett basbyte till en bas bestående av linjärkombinationer av de stokastiska processerna, dessa linjärkombinationer är okorrelerade och är egenvektorer\cite{Shlens_PCA2014} till $C$. Egenvärdena till kovariansmatrisen svarar mot variansen av motsvarande egenvektor.

\begin{comment}
Vid studie av en stokastisk process med flera diskreta komponenter $Y_i(t)$ är det fördelaktigt att definiera en kovariansmatris som beskriver kovariansen mellan dessa komponenter. Kovariansmatrisen definieras enligt 
\begin{equation}
\label{eq:kovmatris}
    C_{ij}(t, t') = \COV{Y_i(t)}{Y_j(t')}.
\end{equation}
Diagonalen i $C_{ij}$ är autokorrelationsfunktioner, det vill säga hur en stokastisk process korrelerar med sig själv, och avdiagonala element är kovariansen mellan komponenenterna $Y_i(t)$ och $Y_j(t')$. Betraktas en stationär stokastisk process så reduceras kovariansmatrisen likt tidigare enligt $C_{ij}(t,t')\to C_{ij}(\Delta t)$ där $\Delta t = |t-t'|$. I denna rapport studeras endast den tidsoberoende kovariansmatrisen
\begin{equation}
    C_{ij} = \ev{C_{ij}(t,t)}_{t}
\end{equation}

Vidare kan kovariansmatrisen $C$ beräknas från observerad data av en samling stokastiska processer $A_i(t)$ där $i=1,2,..n$ och $n$ antal processer. För observerad data under en tid $T$ kan denna således beräknas enligt 
\begin{equation}
\label{eq:covmatrix}
     \COV{A_i}{A_j} \approx \frac{1}{T-1}\sum_{t=1}^T \left(A_i-\bar{A_i}\right)\left(A_j-\bar{A_j}\right),
\end{equation}
från vilket det ses att $C$ är symmetrisk samt reell, givet att $A$ är en reell stokastisk process. Linjär algebra och spektralsatsen medför vidare att den allmänt icke-diagonala symmetriska samt reella kovariansmatrisen är diagonaliserbar. På matrisform blir \eqref{eq:covmatrix} precis $C=\frac{1}{T-1}AA^T$ där $A$ är en matris med de stokastiska processerna $A_i(t)$ som kolonnvektorer. Den diagonaliserade kovariansmatrisen fås då enligt 
\begin{equation}
    D = V^TCV,
\end{equation}
där $D$ är en diagonal matris med egenvärdena till $C$ och $V$ är en matris med egenvektorerna $b_\alpha$ som kolonner. De statistiskt beroende variablerna $A_i(t)$ kan nu uttryckas i basen bestående av egenvektorer som
\begin{equation}
\label{eq:B}
    B_{\alpha}(t) = \sum_i V_{\alpha i}A_i(t),
\end{equation}
för $\alpha = 1,2,..n$. På matrisform kan detta beskrivas med matrisen $B_{\alpha t}$, där varje rad beskriver utvecklingen i tid av koefficienterna $B_{\alpha}$. Betrakta nu kovariansen mellan komponenter till $B_{\alpha}$  enligt 
\begin{equation}
    \COV{B_{\alpha}}{B_{\beta}} = \frac{1}{n-1}BB^T.
\end{equation}
Från ekvation \ref{eq:B} ses att $B=V^TA$ vilket ger 
\begin{equation}
    \COV{B_{\alpha}}{B_{\beta}} = V^TAA^TV = D,
\end{equation}
där enligt tidigare $C=AA^T$, således ses att $B_{\alpha}(t)$ är statistiskt oberoende då alla avdiagonala element i kovariansmatrisen är noll och där de diagonala elementen, egenvärdena till kovariansmatrisen $C$, svarar mot variansen av $B_{\alpha}(t)$. Till skillnad från de stokastiska komponenterna $A_i$ som allmänt ej är statistiskt oberoende så är alltså $B_\alpha$ statistiskt oberoende. %Egenskaper hos kovariansmatrisen samt linjär algebra ger alltså ett recept på hur man utvinner statistiskt oberoende komponenter från en mängd statistiskt beroende. 
\end{comment}

\subsubsection{Spektral effekttäthet}
\todo[inline]{Ska vi nämna något om Wiener-Khinthchine-teoremet?}
Inom signalbehandling kan det vara intressant att veta vilka frekvenskomponenter en signal innehåller. Generellt sett används Fouriertransformen för att ta fram en signals spektrum.
För stokastiska processer kan liknande metoder användas, men tyvärr är i allmänhet stokastiska processer inte Fouriertransformerbara. Istället används den den spektrala effekttätheten, även kallad PSD (en. power spectral density), en nära släkting till Fouriertransformen.

%\paragraph{Energi- och effektinnehåll i en stokastisk process}
Energin i en process $Y(t)$ kan betraktas som integralen
\begin{equation}\label{eq:energy}
E_Y(T) = \int_{-T}^{T} \abs{Y(t)}^2\id{t},
\end{equation}
där $T$ svarar mot den tid som energin mäts över. Anledningen till att stokastiska processer i allmänhet inte är Fouriertransformerbar är att denna integral divergerar när $T\to\infty$. Alltså att $Y$ är divergent i $\mathcal{L}^2$-mening. 

För att få kopplingen att \eqref{eq:energy} svarar mot just \emph{energin} i processen kan $Y(t)$ betraktas som en spänning, vilket ger att $\abs{Y(t)}^2$ är proportionellt mot effekten; integreras sedan en effekt över tid så erhålls en energi. I övriga fall väljer man oftast att kalla motsvarande storheter för energi och effekt trots att de kanske inte strikt sett går att betrakta dem som fysikaliska energier eller effekter. 

För att undvika divergens betraktas istället medeleffekten 
\begin{equation}\label{eq:power}
P_Y(T) = \frac{1}{2T} \int_{-T}^{T} \abs{Y(t)}^2\id{t},
\end{equation}
som för de flesta stokastiska processer oftast~\cite{Miller_probability2012} beter sig bättre än energin.
I det här läget är det också viktigt att påpeka att trots att $P_Y$ kallas medeleffekt, så är det bara medeleffekten av ett visst utfall av den stokastiska processen $Y$, och bör \emph{inte} förväxlas med någon form av väntevärde. 

För att tillslut koppla samman detta med spektraltätheter används den spektrala effekttätheten eller PSD:n
\begin{equation}\label{eq:PSD}
S(f) =  \lim_{T\to\infty}\dfrac{1}{2T} \ev{\abs{\hat{X}_T(f)}^2},
\end{equation} 
där
\begin{equation}\label{eq:truncated_F}
\hat{X}_T(f) = \int_{-T}^{T} X(t)\,\ee^{-\ii 2\pi f t} \id{t}
\end{equation}
är den trunkerade Fouriertransformen av $X$. Genom att ta med kvoten $\nicefrac{1}{2T}$ i \eqref{eq:PSD} erhålls en spektraltäthet av effekter som kan konvergera även om \eqref{eq:truncated_F} på egen hand divergerar när $T\to\infty$. 


\subsection{Skattningar med diskret data} \label{sec:diskret_data}
\todo[inline]{Hur bra är skattningarna.}
Alla dessa verktyg ses bygga på olika väntevärden. Så för att kunna tillämpa
dessa statistiska metoder behövs ett stort statistiskt underlag baserat på
många observationer. Detta eftersom väntevärdet är det medelvärde
som förväntas av en variabel efter tillräckligt många observationer.

Vid statistiska analyser används alltså medelvärdet i en
mätserie för att approximera väntevärden och ges av
\begin{equation}\label{eq:mean}
\ev{X} \approx \bar{x} = \frac{1}{N} \sum_{i=1}^N x_i,
\end{equation}
där $x_i$ är de olika observationerna av $X$ och N dess totala antal. 

När man ska beräkna variansen från ett stickprov kräver båda uttrycken
i \eqref{eq:VAR} två väntevärden. Om inte $\ev{X}$ är känt får man
alltså in två approximationer när man använder \eqref{eq:mean} för att
beräkna väntevärdena i \eqref{eq:VAR}. Detta bidrar bland annat till att en approximation av standardavvikelsen kan göras enligt
\begin{equation}
\sigma_X^2 \approx s_X^2
=  \frac{1}{N-1} \sum_{i=1}^N \left(x_i-\bar{x}\right)^2.
\end{equation}
Detta är standardfelet, $\bar{\sigma}_X$, i kvadrat beräknat med
Bessels korrektion~\cite{Rice_matstat2006}, som innebär att man använder ${N-1}$
i nämnaren istället för bara $N$. Approximationen av kovariansen
följer helt analogt från \eqref{eq:COV}.

\subsubsection{Noggrannheten hos skattningarna}
Genom att utnyttja väntevärdets 


\subsection{Vitt brus och Wienerprocessen}\label{sec:white_noise}
Vitt brus, $\pd_tW_\omega(t)$,\footnotemark{} är ett brus med konstant PSD. Alltså att det, likt vitt brus, har lika mycket av alla frekvenskomponenter. Det går dock att visa att vitt brus uppfyller \cite{Miller_probability2012}
\begin{equation}\label{eq:white_noise}
\begin{aligned}
\ev{\pd_tW_\omega(t)}&=0 \\
\ev{\pd_tW_\omega(t)\pd_tW_\omega(t')}&= \sigma_W^2 \, \delta(t-t'),
\end{aligned}
\end{equation}
samt är normalfördelat. 
Det bör nämnas att äkta vitt brus inte är fysikaliskt eftersom det innehåller oändligt mycket energi. I de flesta tillämpningar brukar dock fluktuationer antas vara vitt brus för att det oftast ger enkla teoretiska analyser. Vidare kan även verkligt brus i många fall~\cite{Engelberg_noise2007} betraktas som vitt till en god approximation -- det vill säga har en konstant spektralfördelning i ett begränsat frekvensintervall.
\footnotetext{Beteckningen med en tidsderivata $\pd_t$ kan verka märklig, men anledningen framgår i stycket nedan. }

%Strikt talat ges en Wienerprocess genom att börja med att betrakta \cite{Miller_probability2012}
%\begin{equation}
%\tilde{W}(t) = \sum_{k=1}^{n} \delta X_i,
%\end{equation}
%där $X_i$ är oberoende stokastiska ''steg'' med som enbart kan anta värdena $1$ och $-1$ med $P(X=1)=P(X=-1)=\nicefrac{1}{2}$, och där $n=t/\Delta{t}$ är antalet steg som tas. Genom att låta $\Delta{t}$ och $\delta$ samtidigt gå mot 0 erhålls en äkta Wienerprocess. 

En Wienerprocess $W_\omega(t)$ är en tidskontinuerlig stokastisk process som kan betraktas som integralen av vitt brus\cite{Miller_probability2012}. Detta är anledningen till att det vita bruset har betecknats som tidsderivatan av en Wienerprocess $\pd_tW_\omega(t)$. Vidare brukar integraltolkningen leda till att Wiernerprocessen beskrivs som den matematiska beskrivningen av brownsk rörelse. 

Ur en praktisk synvinkel är det dock lättare att tänka sig Wienerprocessen som en resultatet av ett antal normalfördelade steg. Betrakta summan
\begin{equation}\label{eq:wiener_approx}
\tilde{W}_n = \sum_{k=1}^{n} \delta X_i,
\end{equation}
där varje steg är $X_i$ är normalfördelat $N(0,1)$ och $n$ är antalet steg. 
Wienerprocessen erhålls sedan i gränsen där $n$ och $\delta$ går mot $0$ samtidigt\cite{Miller_probability2012}. Detta åskådliggör tolkningen av Wienerprocesssen som integralen av vitt brus eftersom summan i viss mån kan tolkas som en Riemannsumma som övergår till en integral i gränsen $n, \delta \to 0$.

Från \eqref{eq:wiener_approx} erhålls att 
\begin{equation}
\ev{\tilde{W}_n} = \delta \sum_{i=i}^n \ev{X_i} = 0
\end{equation}
och
\begin{equation}
\VAR{\tilde{W}_n} = \delta^2 \sum_{i=i}^n \VAR{X_i} = n\delta.
\end{equation}
Genom att betrakta \eqref{eq:wiener_approx} som grunden för en Wienerprocess är det troligt att Wiernerprocessen får liknande egenskaper. Så visar sig också vara fallet~\cite{Miller_probability2012}
\begin{equation}
\begin{aligned}
\ev{W_\omega(t)} &= 0\\
\VAR{ W_\omega(t) } = \ev{ (W_\omega(t))^2 } &\propto t.
\end{aligned}
\end{equation}
Dess egenskaper utnyttjas i avsnitt~\ref{sec:brown} om brownsk rörelse.



\section{Stokastiska differentialekvationer}
En differentialekvation som innehåller termer bestående av stokastiska
processer kallas en stokastisk differentialekvation (SDE). Lösningen
till en SDE kommer representeras av en stokastisk process eftersom
minst en av de ingående termerna är stokastisk. Vilket gör att utvecklingen av systemet är stokastisk.

Inom fysiken modelleras ofta system med fluktuationer genom
att betrakta tidsutvecklingen av ett system via dess styrande
differentialekvation. 
För att studera systemet under påverkan av en stokastisk fluktuation,
exempelvis brus i en elektrisk krets, adderas en term i
differentialekvationen som representerar fluktuationen. 
Detta kallas \emph{Langevinformalism} och motsvarande stokastiska
differentialekvation kallas systemets \emph{Langevinekvation}. 
Ett illustrerande exempel av Langevinformalismen är fallet för
brownsk rörelse som beskrivs i avsnitt~\ref{sec:brown}.

Ett problem som kan uppstå här är att fluktuationens stokastiska fördelning är okänd. Oftast görs dock antaganden om fluktuationen så som att den består av vitt brus som i avsnitt~\ref{sec:white_noise}. 
Antaganden om fluktationens väntevärde och korrelation men med en okänd sannolikhetsfördelning leder till att lösningen till Langevinekvationen endast kan beskriva motsvarande storheter. Alltså studeras under dessa antaganden oftast inte lösningen som sådan, utan istället motsvarande väntevärde samt korrelation för lösningen.  

%\subsubsection{Integrering}
%\todo[inline]{Hur och varför flytta in $\ev{\cdot}$ under integral.}





\subsection{Brownsk rörelse}\label{sec:brown}
Hastigheten för en partikel som utför ren brownsk rörelse styrs av
Langevinekvationen~\cite{Mazo_Brownian2002} 
\begin{equation} \label{eq:Brownian_SDE}
    M\pd_tv=-\zeta v + F(t),
\end{equation}
där $M$ är partikelmassan, $\zeta$ en friktionskonstant och $F(t)$ en
stokastisk, fluktuerande kraft. Kraften utgör här det stokastiska
bidraget och uppfyller egenskaperna för vitt brus enligt \eqref{eq:white_noise}.
Den fysikaliska tolkningen av denna stokastiska kraft är att partikeln
får små impulser från omgivande vätskepartiklar vilka kolliderar
slumpmässigt med partikeln.  
%Denna kraftterm kan vidare tolkas som derivatan av en Wienerprocess i gränsen då kollisionerna infaller med hög frekvens. 
%Motivation att derivata av Wienerprocess s63

Lösningen till den stokastiska differentialekvationen
\eqref{eq:Brownian_SDE} ges av  
\begin{equation}
v(t)
=v(0)\ee^{-\nicefrac{\zeta t}{M}}
 +\frac{1}{M}\int^t_0 F(\tau)e^{-\nicefrac{\zeta (t-\tau)}{M}} \id\tau.
\end{equation}
Detta får dock inte den stokastiska termen att försvinna och lösningen kan inte skrivas på en deterministisk form. För att ändå kunna göra några förutsägelser betraktas väntevärdet och korrelationen i tiden. Korrelationen ges av, där $\delta t\geq0$,
\begin{equation}
\begin{aligned}
\ev{v(t)v(t+\delta t)} 
=& v(0)^2\ee^{-\frac{\zeta}{M}(2t+\delta t)}\\
 &+ \frac{1}{M^2}\ee^{-\frac{\zeta}{M} (2t+\delta t)}
  \int_0^t\int_0^{t+\delta t}\dd\tau\dd\tau'\, 
     \ee^{\nicefrac{\zeta (\tau+\tau')}{M}}\ev{F(\tau)F(\tau')}.
\end{aligned}
\end{equation}
Utnyttja att $F(t)$ korrelerar enligt \eqref{eq:white_noise} vilket ger 
\begin{equation} \label{eq:Brown_korr}
\ev{v(t)v(t+\delta t)} 
= v(0)^2\ee^{-\frac{\zeta}{M}(2t+\delta t)}
 +\frac{\sigma^2}{M^2}\ee^{-\frac{\zeta}{M} (2t+\delta t)}
  \int_0^t\dd\tau\ee^{\nicefrac{2\zeta \tau}{M}}.
\end{equation}
Korrelationen ovan kan nu enkelt beräknas och genom att låta $\delta t\to 0$ samt $t\to \infty$ fås följande samband
\begin{equation}
    \ev{v(t)^2} = \frac{\sigma^2}{2M\zeta}.
\end{equation}

Med hjälp av detta samband samt ekvipartitionsteoremet som gäller vid termisk jämvikt: $\frac{1}{2}M\ev{v^2}=\frac{1}{2}k_BT$, där $k_B$ är Boltzmanns konstant och $T$ är absoluta temperaturen, kan variansen $\sigma^2$ relateras till fysikaliska storheter enligt
\begin{equation}
    \sigma^2 = 2k_BT\zeta.
\end{equation}
Detta resultat är ett exempel på fluktuation-dissipationsteoremet som relaterar dissipationen av energi, friktionen, med fluktuationen, brownsk rörelse. 

För $t \gg \nicefrac{M}{\zeta}$ blir $\pd_t v$-termen i ekvation \eqref{eq:Brownian_SDE} \todo{Visa detta} försumbar och ekvationen kan då skrivas på formen
\begin{equation}
    \zeta \pd_t x=F(t),
\end{equation}
där $x$ är partikelns position. Detta ger lösningen
\begin{equation}
    x(t)=x(0)+\frac{1}{\zeta} \int^t_0 F(\tau)\id\tau.
\end{equation}
Utifrån denna lösning kan medelvärdet av den kvadrerade avvikelsen beräknas, kallat ''mean squared displacement'' (MSD), vilken blir 
\begin{equation}\label{eq:MSD_brown}
    \ev{(x(t)-x(0))^2}=\frac{2k_BTt}{\zeta} \propto t,
\end{equation}
där enligt fluktuation-dissipationsteoremet  $\sigma^2=2k_BT\zeta$. MSD:n kommer därmed att öka linjärt med tiden, något som enkelt kan jämföras med uppmätt data.




%Bara en liten kodsnutt som behövs när man kompilerar lokalt
%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "00main.tex"
%%% End: 